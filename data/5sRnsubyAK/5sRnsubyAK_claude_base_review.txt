30 October 2023, 14:23 (modified: 30 October 2023, 14:23)
Summary: This paper proposes using Constant Q Cepstral Coefficients (CQCC) for the classification of neurodegenerative disorders from speech signals. The authors argue that CQCC leverages geometrically spaced frequency bins to provide superior spectrotemporal resolution compared to traditional features like Mel Frequency Cepstral Coefficients (MFCC). The approach is evaluated on datasets containing speech from individuals with Parkinson's Disease, Amyotrophic Lateral Sclerosis (ALS), and healthy controls. Results show that CQCC outperforms MFCC and traditional acoustic measures (Jitter, Shimmer, Teager Energy) when used with Random Forest and SVM classifiers. The authors attribute this performance to the form-invariance property of the Constant Q Transform, which provides consistent feature representation across varying pitch conditions.
Soundness: 3
Presentation: 2
Contribution: 2
Strengths: The paper addresses an important application area in healthcare, where early detection of neurodegenerative disorders can be critical for treatment. The proposed approach is well-motivated from a signal processing perspective, particularly in how the form-invariance property of CQT can be beneficial for analyzing speech signals with varying characteristics. The experimental evaluation is comprehensive, comparing multiple feature sets across different classification tasks (binary and multi-class) and with different classifiers. The visualization of feature distributions using LDA plots helps to illustrate why CQCC features provide better class separation than MFCC.
Weaknesses: The novelty is somewhat limited as CQCC has been previously applied to other speech analysis tasks, and the paper primarily transfers this technique to neurodegenerative disorder classification without significant adaptation. The experimental methodology has several limitations: the sample sizes are relatively small, and while SMOTE is mentioned to handle class imbalance, details about implementation and potential impacts are sparse. The paper lacks statistical significance testing to validate whether the performance differences between feature sets are statistically meaningful. The presentation has numerous issues with clarity, organization, and English language usage that make it difficult to follow at times. Some mathematical derivations are presented without clear connections to the primary contributions.
Questions: 1. How does the performance of CQCC compare to state-of-the-art deep learning approaches for this task?
2. Why does SVM perform significantly worse than Random Forest when using CQCC for binary classification (99.0% vs 63.4% in Table 4), but perform better in the ALS vs PD classification task (86.1% vs 80.5% in Table 6)? 
3. Could you clarify how the hyperparameters for CQCC extraction (such as the number of bins per octave) were selected? Was any optimization performed?
4. How robust are the proposed features to different recording conditions and equipment, which would be critical for real-world clinical applications?
Flag For Ethics Review: 
Rating: 5
Confidence: 4
Code Of Conduct: yes