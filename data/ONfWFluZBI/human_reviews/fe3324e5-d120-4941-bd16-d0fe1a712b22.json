{"summary":"In this paper, the authors propose a system-identification scheme for non-linear observations of non-linear time series data. In particular, they propose a modified contrastive learning set-up that posits linear latent dynamics. Compared to prior works in (time) contrastive learning, this directly enforces a notion of sequential temporal consistency, and seems to provide some benefit in system identification settings. Some supporting theory is provided, demonstrating that if the underlying dynamics are linear and invertible, then the proposed method asymptotically recovers the true dynamics up to affine ambiguity. For general non-linear systems, a (soft) switched-linear system heuristic is proposed, where Jacobian linearizations are applied at user-provided reference points.","soundness":"3: good","presentation":"3: good","contribution":"2: fair","strengths":"Automatic identification of latent variables or dynamics is of critical importance in modern machine / reinforcement learning. The method the authors propose follows a line of self-supervised methods in contrastive learning. In comparison to its closest relative in time-contrastive learning (Hyvarinen and Morioka, 2016), the proposed method is seemingly more well-fit for fitting non-linear time-series data by fitting a latent time-series, rather than predicting a categorical label as in the aforementioned paper.\n\nSince a main inductive bias built into the base method is that the latent dynamics are linear, the proposed method of iterative Jacobian linearizations is a sensible adaptation, and seems to benefit performance significantly.\n\nNumerically, the proposed method appears to make contrastive methods more robustly performant.","weaknesses":"In my opinion, the paper leaves quite a few critical questions unanswered, and in general suffers from a lack of polish. In its current state, I cannot recommend the paper for acceptance. The main weaknesses in my eyes are the following:\n\nThe paper claims to perform latent nonlinear system identification. This is a key desideratum in various fields such as reinforcement learning and continuous control, and thus has a rich history and literature. However, the assumptions in this paper--and notably how these inductive biases propagate to the algorithm design--severely restrict the applicability of the method without further evidence. Notably, a design assumption in this paper is that the observer function (i.e.\"mixing function\") is invertible. This is a very strong assumption in the context of non-linear system identification, where even the foundational theory of linear system identification does not presume: in the Linear-Quadratic Gaussian (LQG) model, where the underlying state evolves linearly \n, and observations are a linear function of state \n (ignoring the control input term for simplicity), the classical set-up has \n, such that the observations are per-timestep a low-dimensional measurement of the underlying state. This immediately rules out the mixing function \n being invertible, and this is precisely the motivation for notions such as observability/detectability. Partial observability presents the key challenge in non-linear sysID or reinforcement learning. In particular, it is well-known in controls and RL that ignoring partial observability and imposing a Markovian model (which this paper does implicitly by enforcing the state estimate as a function solely of the current observation) can lead to very undesirable outcomes. In the contrastive learning literature, partial observability is usually not a central issue, often because it is irrelevant for the motivating application (e.g. in computer vision), but one must address this problem for time-series data. In fact, the cited Time-Contrastive Learning method (Hyvarinen and Tomioka, 2016), despite making the same assumption in theory, actually propose a method that is more amenable to partial observability, since they predict categorical labels to chunks of observed data.\n\nRegarding the polish of the paper, there are various typos and lacking definitions that make the paper hard to parse at times. The minor ones that I have caught are listed below. A particularly confusing point is the role of the control input \n. The paper presents the control input as entering the latent dynamics directly. However, it is typically the case that the control input enters the state through a (possibly state-dependent) actuation matrix \n. In any case, how the control input enters the dynamics should be dependent on the parameterization of the dynamics, e.g. the affine ambiguity in \n in the paper, which is not reflected in the authors' method as far as I can tell. Furthermore, it is unclear if the control input is available to the learner (which is usually the case in sysID), or if it is playing the role of stochastic noise, which eq (9) seems to suggest compared to eq (1). In either case, what role is the control input playing here: in the authors' set-up, there is no need to learn the actuation matrix, and the experiments involve learning a low-noise, nearly deterministic Lorenz system, which rules out some persistency of excitation effect (Tsiamis and Pappas, 2019).\n\nMinor comments/typos:\n\nFigure 1: x -> \n\nPage 3: \"linear identifiability (...)\", missing eqref?\n\nTheorem 1: \"bijective dynamics model \n\", should probably mathematically define what that means.\n\nTheorem 1: \n is not defined in the main paper, only in the appendix.\n\nCorollary 1: \"\n\", seems to be bad notation.\n\nBeginning of Sec 4: \"non-lineary\" -> \"non-linearly\"\n\nEquation (7): where is \n defined? Possible hash collision with mixing function notation.\n\nTable 1: should probably introduce acronym \"LDS\" = Linear Dynamical System somewhere\n\nTable 1: What does LDS\n mean?\n\nTable 1: What do \n, \n, \n, \n in the theory column indicate?\n\nBetween (11) and (12): \"tailor\" -> \"Taylor\"\n\nBefore Sec 5: \"matices\" -> \"matrices\"\n\nImplementation paragraph: possibly missing number of A100 cards?\n\nEq (23): where is \n defined?\n\nEq (25): what does \n denote precisely?\n\nAfter Eq (50): \"which is probably still fine because \n is a valid kernel function (?)\". This probably needs to be formalized/reworded.\n\nReferences:\n\nAnastasios Tsiamis and George J. Pappas, \"Finite Sample Analysis of Stochastic System Identification\", 2019.","questions":"My main questions can be summarized as follows:\n\nWhat is the marginal utility of this method rather than various other latent nonlinear dynamics estimation methods, e.g. (Watter et al., 2015) (which in fact also imposes locally linear latent dynamics), which do not make strong assumptions on identifiability?\n\nHow does enforcing the identifiability/invertibility conditions in this paper affect the method's performance in partially observed settings? This could be as simple as the LQG setting detailed above. Does this strong inductive bias translate to large errors when it is not satisfied (which is typically the case when only provided with observations of a ground-truth belief/latent state)?\n\nAs detailed above, what is the role of the control input? What is the effective difference of the proposed setting and an autonomous (latent) dynamical system \n?\n\nFrom a practical perspective, how are the reference points for computing first-order linear approximation in the switching case chosen? Also, do these need to be recomputed per iteration, since the parameterization of \n changes per iteration?\n\nReferences:\n\nWatter et al., \"Embed to Control: A Locally Linear Latent Dynamics Model for Control from Raw Images\", 2015.","ethics_flag":"No ethics review needed.","ethics_concerns":null,"rating":"6: marginally above the acceptance threshold","confidence":"3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.","code_of_conduct":true}