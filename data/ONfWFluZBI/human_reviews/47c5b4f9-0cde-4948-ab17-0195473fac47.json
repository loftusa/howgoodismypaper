{"summary":"The paper \"Self-Supervised Contrastive Learning Performs Non-Linear System Identification\" explores contrastive learning (CL) for identifying non-linear temporal representations. It presents proof of the identifiability of latent variables up to a linear transformation, removing the requirement for independent noise. The proposed model, DynCL, is validated using synthetic data to support the theoretical findings. Additionally, the authors introduce a model called delta-SLDS, designed to capture switching between linear and non-linear dynamic systems.","soundness":"3: good","presentation":"2: fair","contribution":"3: good","strengths":"The theorem is both interesting and novel, demonstrating that the learned latent variables can be identifiable up to linear transformations even in the absence of independent noise, provided that some other assumptions are met.\nThis theorem provides valuable insights into the mechanisms underlying contrastive self-supervised learning methods.\nA lot of ablation studies and visualization experiments are conducted, which makes the paper more convincing.","weaknesses":"Notations are not clear. For example, in Eq (3), the meanings of \n should be mentioned in advance.\nIn theorem (1) and its proof, the assumption is not aligned with Equation (1-2), where all noise disappears. Further discussion is required.\nThe difference in theorem part should be compared with previous works on CL more detailed, since it is a work focusing on theorem. Making the difference more clear will make it more readable.\nIn experiment parts\nBaselines like TCL should be compared\nBy identifiability, some metrics like MCC should be compared even though they are not component-wise identifiable.\nLots of typos:\nline 133 (supp figure), line 145 (...), seems unfinished part\nline 250: tailor -> talyor\nline 637: Theorem 2 -> Theorem A1\nfootnote of page 13: broken reference\nline 659, 665: missing reference","questions":"It is confusing why it requires 120 GPU days on A100 for these synthetic data. Methods like TCL require only dozens of minutes for one synthetic data. What is the detailed model structure with approximate parameter size?","ethics_flag":"No ethics review needed.","ethics_concerns":null,"rating":"6: marginally above the acceptance threshold","confidence":"3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.","code_of_conduct":true}