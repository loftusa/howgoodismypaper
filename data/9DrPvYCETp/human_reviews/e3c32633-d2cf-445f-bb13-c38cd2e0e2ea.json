{"summary":"This paper introduces the Shared Recurrent Memory Transformer (SRMT), a novel model in multi-agent reinforcement learning designed for multi-agent lifelong pathfinding tasks. SRMT extends memory transformers to decentralized multi-agent environments by pooling individual agent memories into a shared memory space, allowing agents to indirectly share information and coordinate. The model is tested in various pathfinding tasks, including bottleneck navigation and complex environments from the POGEMA benchmark. SRMT demonstrates superior performance in coordination and generalization, particularly in high-density and partially observable environments.","soundness":"3: good","presentation":"3: good","contribution":"3: good","strengths":"The SRMT model is an adaptation of memory transformers to multi-agent settings, facilitating indirect communication among agents through a shared memory. This approach addresses a significant challenge in decentralized coordination by leveraging shared recurrent memory, which is unique compared to conventional communication strategies.\nThe paper provides a rigorous evaluation of SRMT on multiple benchmark tasks, including POGEMA and bottleneck navigation. The use of diverse reward settings (e.g., sparse, directional) further strengthens the experimental framework, revealing SRMT’s adaptability in various coordination scenarios.\nThe architecture and methods are clearly explained, supported by diagrams and flowcharts that help clarify SRMT’s working mechanism. The comparisons with baselines and the explanation of the multi-agent Markov decision process formulation are presented in a straightforward and understandable manner.\nSRMT’s ability to handle decentralized pathfinding without explicit communication protocols has considerable implications for real-world applications, particularly in settings where communication might be unreliable or costly. Its effectiveness across different maps and scenarios demonstrates potential for scalability in complex, large-scale environments.","weaknesses":"While SRMT performs well on small to medium-sized environments, its scalability to very large maps or highly dense environments remains uncertain. The evaluation could be extended to more challenging settings, particularly with greater agent populations or larger obstacles, to fully assess SRMT’s scalability.\nWhile SRMT is designed for decentralized systems, it would be beneficial to see comparisons with centralized approaches on key metrics to understand the trade-offs better, particularly in environments that demand high coordination.\nWhile the paper claims that shared memory improves coordination, additional analysis on how shared memory influences individual agent behavior would provide a deeper understanding. An ablation study removing the shared memory aspect could further validate its impact on SRMT’s performance.\nThe model's performance varied across different reward structures, and while this is discussed, a more detailed exploration of how reward shaping influences learning would strengthen the analysis. This would help in tailoring SRMT to tasks where only sparse rewards are available.\nMissing references (MARL with local information). I believe these are quite recent papers and work in a similar setting as mentioned in the related works section.\n\n[1]: Hu, Y., Fu, J., & Wen, G. (2023). Graph soft actor–critic reinforcement learning for large-scale distributed multirobot coordination. IEEE transactions on neural networks and learning systems.\n\n[2]: Nayak, S., Choi, K., Ding, W., Dolan, S., Gopalakrishnan, K., & Balakrishnan, H. (2023, July). Scalable multi-agent reinforcement learning through intelligent information aggregation. In International Conference on Machine Learning (pp. 25817-25833). PMLR.","questions":"How well does SRMT scale with an increased number of agents or more complex map structures? Additional experiments in larger environments could help evaluate its robustness in real-world applications.\nWould SRMT benefit from combining shared memory with limited explicit communication for certain high-density environments?\nHow does shared memory impact the decision-making process for individual agents? Further analysis on memory usage patterns and shared memory dynamics could provide insights into SRMT’s internal coordination mechanisms.\nDoes SRMT allow for integration with hierarchical pathfinding methods, such as combining local and global pathfinding strategies?","ethics_flag":"No ethics review needed.","ethics_concerns":null,"rating":"8: accept, good paper","confidence":"4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.","code_of_conduct":true}