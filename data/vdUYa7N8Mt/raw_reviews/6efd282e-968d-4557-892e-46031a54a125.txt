Summary:
The paper concerns with the rate-distortion-perception tradeoff (RDP) in the context of lossy compression and argues that previous theoretical results, which suggest that common randomness between the encoder and the decoder is crucial for good performance, do not accurately reflect how humans perceive realism. To address this, the authors reformulate the RDP with reaslim constraints by adopting the concept of universal critic that generalizes no-reference metrics and divergences and insecpt batches of samples. Under this framework, they prove that near-perfect realism is achievable without common randomness unless the batch size is impractically large and the proposed realism measure reduces to a divergence.

Soundness: 3: good
Presentation: 2: fair
Contribution: 2: fair
Strengths:
The paper provides a novel perspective on the rate-distortion-perception tradeoff by adopting the concept of universal critics.
The paper presents rigorous theoretical analysis and proofs to support its claims.
The theoretical finding that near-perfect realism is achievable without common randomness has significant practical implications for lossy compression.
Weaknesses:
While the paper presents a novel and potentially impactful contribution, its clarity and accessibility are hindered by a dense presentation style. The heavy use of technical notation and the lack of illustrative examples make it challenging to grasp the core concepts and implications of the proposed framework.

Specifically, the paper would benefit from:

More explanatory discussions: For instance, a concise discussion following Definition 3.3 would clarify the meaning and significance of the new formulation in comparison to the original RDP framework.

Illustrative examples: Simple case studies or visual examples would help readers understand the practical implications of the theoretical results. The authors could consider drawing inspiration from the original RDP paper by Blau & Michaeli, which effectively uses examples to convey its ideas.

Addressing these issues would make the paper more accessible to a wider audience and increase its impact. While the core contribution merits acceptance, I strongly encourage the authors to revise the paper with a focus on clarity and illustrative examples.

Questions:
Does common randomness offer any benefits beyond perceptual realism in lossy compression? For example, stability/robustness?
How does the achievable rate-distortion-perception tradeoff change as a function of the batch size used by the universal critic? Does this analysis offer any insights into selecting an appropriate batch size for training generative compression models that aim to satisfy perceptual quality constraints?
Flag For Ethics Review: No ethics review needed.
Rating: 5: marginally below the acceptance threshold
Confidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.
Code Of Conduct: Yes