{"summary":"This paper introduces a sparsity-aware machine unlearning method. First, it proposes to adaptively identify influence-critical parameters using a derived score function. Then, it applies existing machine unlearning methods (e.g., second-order unlearning) exclusively to optimize the identified parameters. The process of parameter identification and optimization is performed iteratively.","soundness":"3: good","presentation":"2: fair","contribution":"2: fair","strengths":"The approach to identifying influence-critical parameters based on the retain set (and the forget set) appears original. The derivation is clear and reasonable. (However, the necessity needs clarification, as mentioned in the weaknesses below.)\nThe paper is well-organized and easy to understand.\nIt is meaningful to explore the applications of the proposed method for both memory-free and memory-aided successive machine unlearning scenarios.","weaknesses":"In line 273, it appears that the differentiation is performed on \n rather than \n.\nDoubts regarding the necessity of the proposed parameter identification approach. The authors derive a score function to identify informative parameters, involving calculating the derivative with respect to \n over \n and \n. Why not directly optimize the mask parameters base on Eq.(4), which seems computationally cheaper and simpler with only once gradient calculation? Or why we need to transform Eq.(4) to Eq.(5)?\nDoubts about the claimed efficiency benefits. The paper claims improved efficiency for machine unlearning, but this may not be the case:\nComputation: Compared to vanilla second-order unlearning, the proposed method requires additional calculations involving twice the differentiation to identify informative parameters and still requires computing gradients for all parameters during the unlearning phase.\nMemory: Although masking hides certain parameters, storing the mask and associated gradients requires extra memory.\nInsufficient complexity analysis. A comprehensive analysis is needed, detailing the complexity of both the parameter identification and unlearning phases from perspectives like memory and computation.\nWhat are the specific advantages of the proposed method for the successive machine unlearning? The descriptions (e.g., in Line 362) is too broad and hard to understand. Detailed, clear and reasonable analysis is needed.\nIt is recommended to use the standard notation format as outlined by ICLR guidelines instead of using a uniform font throughout all equations. The correct formatting guidelines can be found on the official website.","questions":"Why do we need a layer-wise optimization (Eq.(9)) in addition to the individual optimization (Eq.(8)) during the mask selection process?\nHow is the first item in Eq.(13) derived? It is hard to follow the method description in Sec.3.3.2.","ethics_flag":"No ethics review needed.","ethics_concerns":null,"rating":"5: marginally below the acceptance threshold","confidence":"3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.","code_of_conduct":true}