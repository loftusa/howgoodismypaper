{"summary":"The authors tackle the challenge of efficient machine unlearning in large Transformer models, essential for meeting privacy regulations. Existing methods, often structure-agnostic, struggle to accurately target influence-critical parameters in Transformers. To address this, the authors introduce SPE-Unlearn, a structure-aware approach that uses learnable masks to identify key parameters within Transformer heads and filters. Optimized via a greedy search, SPE-Unlearn enhances unlearning by balancing efficiency and effectiveness. Extensive experiments show that SPE-Unlearn significantly improves unlearning performance across various Transformer models and datasets.","soundness":"2: fair","presentation":"2: fair","contribution":"2: fair","strengths":"The paper is clearly written, well-formatted, and well-organized.\n\nThe mathematical derivations are rigorous.","weaknesses":"The paper mentions that SPE-Unlearn can enhance the effectiveness of various methods; however, the authors only integrate SPE-Unlearn with SO and do not test it with other methods. In Table 2, SPE-SO does not show a significant improvement over SO, while requiring more time.\n\nCommon LLM unlearning tasks, such as TOFU, MUSE, and WMDP, are missing.\n\nSeveral standard baselines, like NPO and \"I don't know,\" are not included, which weakens the argument.\n\nFor robustness, the authors employ memory-free and memory-aided unlearning but do not explore other approaches, such as jailbreak prompts.","questions":"Could the authors explore additional LLM unlearning benchmarks, such as TOFU, MUSE, and WMDP?\n\nCould the authors evaluate more unlearning methods, like NPO and \"I don't know\"?\n\nFor robustness evaluation, would it be possible to include tests like relearning attacks or jailbreak prompts?\n\nAdditionally, could the authors consider using gradient norm alone to identify saliency? This might offer a more streamlined approach.","ethics_flag":"No ethics review needed.","ethics_concerns":null,"rating":"3: reject, not good enough","confidence":"4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.","code_of_conduct":true}