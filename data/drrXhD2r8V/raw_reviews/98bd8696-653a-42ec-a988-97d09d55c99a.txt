Summary:
This paper proposes an efficient unlearning method with multiple benefits, such as reduced time and memory costs. The proposed method is a pruning-based unlearning approach that filters out sensitive weights to forget specific data. By converting to a differential formulation for the masking variable, the authors approximate unlearned weights through a combination of masking and the Fisher information matrix. Using a second-order Taylor expansion and the convergence assumption from LeCun et al., the method is simplified to this combination. In experiments, the authors compare their approach to prior methods and report promising performance.

Soundness: 2: fair
Presentation: 3: good
Contribution: 2: fair
Strengths:
I believe the strongest benefit of this work is its time and memory efficiency. Across all tables, the authors report significantly reduced costs for unlearning, which highlights a promising advancement in the field of machine unlearning.

Weaknesses:
However, I have several concerns:

It is unclear why the method is considered structure-aware. While mask variables are applied to each head in the multi-head attention block, this approach is not unique to Transformers. The authors mention as "widely-adopted unlearning methods in Transformers, e.g., fine-tuning (Golatkar et al. (2020)) and gradient difference (Liu et al. (2022); Jia et al. (2024))," but they are not specified to transformer architecture. As I understand from the manuscript, the authors suggest that their method’s efficiency makes it well-suited to large-scale Transformer models, but large scale is not a Transformer-specific attribute.

Although the method is not specialized for Transformer architectures, much of the paper focuses on Transformer-specific content. Reducing this content could make the paper more concise and focused.

In line 190, the authors assume that " L is differentiable with respect to m", to develop Equations (5-9). However, as stated in line 160, 
 is a binary variable. This raises concerns about whether the differentiability assumption is valid.

In line 181, the authors state, "we formulate the unlearning objective (1) with a learnable pair of masks for the heads and filters as a constrained optimization problem." However, objective (1) aims to retain a model with the same architecture trained only on D_r. The proposed method, which involves pruning, alters the architecture, making it misaligned with this objective.

The experimental section lacks details on the partitioning of D_r and D_f. This split is an essential part of the experimental setup and should be clearly specified.

Evaluation Concerns in Table 2 and Appendix:

6-1) The unlearning performance should be evaluated by comparing it to the performance of a retrained model, as specified by Eq (1). In specific, the MIA metric should follow this protocol, with retrained models serving as the gold standard. However, the authors set the lower values of efficacy and higher values of fidelity are better without any explanation.

6-2) In Table 1, the proposed method unlearns to a greater extent (achieving 85.94% as the lowest Unlearning Accuracy) than other methods, resulting in lower Remaining Accuracy. To ensure a fair comparison, it would be better to report Remaining Accuracy and Testing Accuracy at the point where each method reaches a common Unlearning Accuracy threshold.

6-3) All methods (FT, GD, SA) have hyperparameters that control unlearning speed, such as learning rate, but there is no discussion of these parameters in the manuscript. Without this information, it’s unclear whether the evaluations are fair.

6-4) The authors used only D_r for Fine-Tuning (FT) and Sparsity-Aware Unlearning (SA) but used both D_r and D_f for their method. This discrepancy in dataset usage should be clarified, and comparisons with more unlearning methods that use both D_r and D_f are recommended.

6-5) Many of the unlearning methods used for comparison are outdated. It would strengthen the evaluation to include more recent works, such as:

[1] Fan, C., Liu, J., Zhang, Y., Wong, E., Wei, D., & Liu, S. (2023). Salun: Empowering machine unlearning via gradient-based weight saliency in both image classification and generation. arXiv preprint arXiv:2310.12508.

[2] Chen, M., Gao, W., Liu, G., Peng, K., & Wang, C. (2023). Boundary unlearning: Rapid forgetting of deep networks via shifting the decision boundary. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 7766-7775).

(Minor) In the second sentence of the Related Work section, "Jang et al." is cited twice in a single sentence.
Questions:
See above

Flag For Ethics Review: No ethics review needed.
Rating: 6: marginally above the acceptance threshold
Confidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.
Code Of Conduct: Yes