Summary:
This article proposes a meta-heuristic to improve time series classification algorithms by classifying random windows and aggregating scores. The algorithm is tested on a real-world task where it achieves promising performance.

Soundness: 2: fair
Presentation: 3: good
Contribution: 3: good
Strengths:
The article is well-written and easy to follow.
The methodology is sound and has the potential to provide an interpretable time series classification strategy that can be combined with virtually any time series classification algorithm.
Weaknesses:
The proposed approach is simple, which is perfectly fine, but lacks a more thorough analysis, at least empirical. For a reader with a use case in mind, it is difficult to assess if this method is appropriate.
Another drawback is that this approach has only been tested on one data set. To assess its generalization capability, the authors could test their method on additional publicly available time series datasets.
Section 4.5 on qualitative interpretation needs to (re)written to be more convincing as it lacks much information or comments. Interpretability is one of the contributions listed in the introduction.
Questions:
Approaches based on convolutions can handle variable lengths, and the number of parameters does not increase with the signal length, contrary to what is stated in the section on related work. Can the authors clarify or revise their statement about convolutional approaches in the related work section?
The sampling is said to be sparse. How does the performance vary with the number of drawn windows? Consider doing an ablation study or experiment showing performance as a function of the number of sampled windows.
To improve the statistical rigor of the results, can the authors report standard deviations or confidence intervals for all reported performance metrics?
Certain notations can be misleading : 
 is an integer while 
 is vector. Consider changing them to more consistent notations.
Current baselines are mostly deep-learning-based, but many other classification algorithms exist [1]. Can the authors include a few other baselines that they think are relevant?
In Section 4.5, what are the labels of the displayed signals? Do they belong to the same individual? Are the highlighted areas related to a known physiological phenomenon?
How important is the smoothing step presented in Section 3.2.2? Its influence could be for instance illustrated with an ablatio study.
[1] Ruiz, A. P., Flynn, M., Large, J., Middlehurst, M., & Bagnall, A. (2021). The great multivariate time series classification bake off: a review and experimental evaluation of recent algorithmic advances. Data Mining and Knowledge Discovery, 35(2).

Flag For Ethics Review: No ethics review needed.
Rating: 5: marginally below the acceptance threshold
Confidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.
Code Of Conduct: Yes