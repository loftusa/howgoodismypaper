{"summary":"This article proposes a meta-heuristic to improve time series classification algorithms by classifying random windows and aggregating scores. The algorithm is tested on a real-world task where it achieves promising performance.","soundness":"2: fair","presentation":"3: good","contribution":"3: good","strengths":"The article is well-written and easy to follow.\nThe methodology is sound and has the potential to provide an interpretable time series classification strategy that can be combined with virtually any time series classification algorithm.","weaknesses":"The proposed approach is simple, which is perfectly fine, but lacks a more thorough analysis, at least empirical. For a reader with a use case in mind, it is difficult to assess if this method is appropriate.\nAnother drawback is that this approach has only been tested on one data set. To assess its generalization capability, the authors could test their method on additional publicly available time series datasets.\nSection 4.5 on qualitative interpretation needs to (re)written to be more convincing as it lacks much information or comments. Interpretability is one of the contributions listed in the introduction.","questions":"Approaches based on convolutions can handle variable lengths, and the number of parameters does not increase with the signal length, contrary to what is stated in the section on related work. Can the authors clarify or revise their statement about convolutional approaches in the related work section?\nThe sampling is said to be sparse. How does the performance vary with the number of drawn windows? Consider doing an ablation study or experiment showing performance as a function of the number of sampled windows.\nTo improve the statistical rigor of the results, can the authors report standard deviations or confidence intervals for all reported performance metrics?\nCertain notations can be misleading : \n is an integer while \n is vector. Consider changing them to more consistent notations.\nCurrent baselines are mostly deep-learning-based, but many other classification algorithms exist [1]. Can the authors include a few other baselines that they think are relevant?\nIn Section 4.5, what are the labels of the displayed signals? Do they belong to the same individual? Are the highlighted areas related to a known physiological phenomenon?\nHow important is the smoothing step presented in Section 3.2.2? Its influence could be for instance illustrated with an ablatio study.\n[1] Ruiz, A. P., Flynn, M., Large, J., Middlehurst, M., & Bagnall, A. (2021). The great multivariate time series classification bake off: a review and experimental evaluation of recent algorithmic advances. Data Mining and Knowledge Discovery, 35(2).","ethics_flag":"No ethics review needed.","ethics_concerns":null,"rating":"5: marginally below the acceptance threshold","confidence":"3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.","code_of_conduct":true}