{"summary":"The paper focuses on the solution to recovering the plasticity of DNNs via weight regularization. The paper proposes a simple yet effective weight regularization method that prevents unbounded weight growth. The authors also provided the technique's theoretical and empirical insights, which prove the generalization performance in different learning.","soundness":"3: good","presentation":"3: good","contribution":"3: good","strengths":"This work progressively establishes and justifies its framework, making this paper easy to follow.\nThe results are promising, however, I have some concerns regarding the results as discussed below","weaknesses":"One main drawback of the paper is the limited application of the paper. The authors made many assumptions (e.g., the network is affine, homogeneous with ReLU), which impedes the contributions and the applicability of the paper in real-world scenarios.\nSome crucial statements are made without proper references. Furthermore, these statements are conflicted with the statements in various peer-reviewed and significant publications.\nThe paper came up with many theorems and definitions without explaining the usages and necessities of these statements.\nAblation tests according to Theorem 1 needed to be conducted to verify the paper's significance.\nAll in all, the aforementioned issue impedes the contribution and significance of the paper method. The authors please consider carefully about these issues. If the issues are addressed, the score can be modified.\nThe experimental evaluations are not sufficient, they need to provide more experiments on large-scale datasets (ImageNet1K, COCO, etc) and across different model architectures (VisionTransformers, etc).\nThe hyper-parameter \n is proposed but there are no experiments that consider the effect of \n on the boundedness of the weight before and after scaling.\nThere should be a theoretical discussion about how to tighten the boundedness compared to other methods. For example, in Theorem 2, the authors show that \n, which is trivial thus not proving that the proposed method is better than others.","questions":"Can you discuss more the statement in L086: \"weight growth is inevitable in deep learning\"? We agree that a large value of weight norm impedes the model generalization. However, this phenomenon is usually at the initial phase of DL. It can be proved via empirical experiments [R1], or theoretical [R2, Theorem 1].\nMoreover, in the cited paper, the authors mentioned the phenomenon when the weight norm is large. However, the authors did not mention that the weight norm is high due to the progress of the training model (which is related to the plasticity effects of the pre-trained model, which is already trained). Please note that this statement is crucial to assess the paper's contribution and significance.\n[R1] Yang You, Jing Li, Sashank Reddi, Jonathan Hseu, Sanjiv Kumar, Srinadh Bhojanapalli, Xiaodan Song, James Demmel, Kurt Keutzer, Cho-Jui Hsieh, Large Batch Optimization for Deep Learning: Training BERT in 76 minutes, ICLR 2020.\n\n[R2] Jianyu Wang, Qinghua Liu, Hao Liang, Gauri Joshi, H. Vincent Poor, Tackling the Objective Inconsistency Problem in Heterogeneous Federated Optimization, NIPS 2020.\n\nWhat is the necessity of the notations of the network layer defined as in L130-136?\nIn 156, \n is the proportion of the output of the model, is it applicable to models with various types of activation functions or only applicable to linear activation functions?\nWhat is the meaning of Theorem 1? Why do we need to find many networks that are proportional with \n?\nIn L216 - L218, can the authors discuss more the statement that the \"initial weight norm is small in most initialization\"? To be frank, this statement needed to be considered carefully (e.g., making ablation tests or empirical evaluations).\nIn L245, why \n is set to 1? Is it different in performance if we set \n to different values? An ablation test according to the difference initial C should be made to verify the paper's method.","ethics_flag":"No ethics review needed.","ethics_concerns":null,"rating":"3: reject, not good enough","confidence":"4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.","code_of_conduct":true}