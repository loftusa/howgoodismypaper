15 February 2024, 10:30 (modified: 15 February 2024, 10:30)
Summary: This paper proposes a hybrid batch training strategy for optimizing multilingual information retrieval models that can simultaneously handle monolingual, cross-lingual, and multilingual retrieval tasks. The approach combines monolingual and cross-lingual question-answer pair batches during training, with sampling probabilities adjusted based on dataset size. The authors evaluate their method on established benchmarks including XQuAD-R, MLQA-R, and MIRACL, showing that it achieves comparable or better performance across all retrieval settings while significantly reducing language bias compared to monolingual-only training approaches. The proposed method is simple yet effective, requiring no architectural changes or specialized loss functions.

Soundness: 3
Presentation: 3
Contribution: 3
Strengths: The paper addresses an important challenge in multilingual information retrieval by proposing a simple yet effective training methodology. The hybrid batch training approach is intuitive and requires minimal modifications to existing training pipelines. The paper includes comprehensive evaluation across multiple datasets, languages, and pre-trained models, demonstrating consistent improvements across various metrics. The proposed method effectively reduces language bias, which is particularly important for multilingual retrieval tasks. The zero-shot generalization to unseen languages is a particularly impressive aspect of the approach, suggesting its potential applicability to low-resource languages.

Weaknesses: While the methodology is sound, the novelty of the approach is somewhat limited as it simply combines existing training strategies without introducing fundamentally new techniques. The hyperparameter tuning process for determining the optimal values of α and β could be better explained, particularly regarding how the authors concluded that 0.5 was the optimal value. The paper lacks theoretical analysis of why the hybrid batching approach works well, relying primarily on empirical observations. The evaluation, while comprehensive, doesn't adequately address potential trade-offs or limitations of the approach, such as increased training time or resources required. The paper doesn't compare against more recent state-of-the-art approaches for multilingual information retrieval beyond the two baselines mentioned.

Questions: 1. How does the training time of the hybrid batch approach compare to monolingual-only or cross-lingual-only approaches? Is there a computational trade-off for the improved performance?
2. Have you explored different sampling strategies beyond the simple probabilistic approach? For example, would a curriculum learning approach where the ratio of monolingual to cross-lingual batches changes during training be beneficial?
3. The paper mentions that α values between 0.4 and 0.6 provide similar performance. Have you explored if this range changes for different language pairs or if it's consistent across all evaluated settings?
4. How does the proposed approach handle languages with different writing systems or linguistic characteristics? Is there any analysis on whether the performance improvements are consistent across language families?

Flag For Ethics Review: No
Rating: 6
Confidence: 4
Code Of Conduct: Yes