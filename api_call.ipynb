{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ndif reviewer scores\n",
    "reviewer_1 = \"\"\"\n",
    "Official Review of Submission11061 by Reviewer RQ4u\n",
    "Official Reviewby Reviewer RQ4u04 Nov 2024, 12:56 (modified: 02 Dec 2024, 10:19)EveryoneRevisions\n",
    "Summary:\n",
    "The paper introduces two systems NNsight and NDIF that collectively aim to reduce the developer and hardware costs of analyzing and modifying the inference behavior of open-source models. NNsight is an instrumentation framework for PyTorch models, while NDIF is an inference service that enables deferred execution of NNsight instrumentations on a remote shared model deployment. The paper provides evaluation comparing to inference baselines of shared (Petal) and non-shared HPC deployments.\n",
    "\n",
    "Soundness: 3: good\n",
    "Presentation: 3: good\n",
    "Contribution: 3: good\n",
    "Strengths:\n",
    "This paper is focusing on an important problem since tools that enable introspection of model internals are extremely valuable for ML research and applications.\n",
    "Opting for Pytorch-native tools is a great design choice as that significantly reduces development and integration burden for practitioners.\n",
    "Enabling resource sharing via NDIF service is very useful to democratizing access to SOTA models.\n",
    "Weaknesses:\n",
    "The paper seems to overclaim, particularly in the title and abstract, that the work applies to foundation models in general, when in reality it only applies to open-source models, since model internals knowledge is required to create interventions. The authors should more carefully scope the claims.\n",
    "The evaluation does not study co-tenancy scenarios where the NDIF is servicing multiple NNsight requests. This is a significant oversight considering that the resource sharing benefits of NDIF is a major contribution of the work. The authors should include results showing not just the performance implications of servicing the multiple NNsight requests but also validating the correctness of the co-tenancy features.\n",
    "Questions:\n",
    "Do users submit a pair of NNsight request and an input prompt? Or how is the input prompt for exercising an intervention generated?\n",
    "When multiple NNsight requests are submitted, are all the interventions applied to a single model instance for inference, or is a separate model instance created for each request?\n",
    "If a single model instance is instrumented with multiple NNsight requests, how does NDIF ensure that a request that modifies model parameters does not affect other requests?\n",
    "How is KV-cache managed for multiple NNsight requests?\n",
    "Flag For Ethics Review: No ethics review needed.\n",
    "Rating: 6: marginally above the acceptance threshold\n",
    "Confidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\n",
    "Code Of Conduct: Yes\n",
    "\"\"\"\n",
    "\n",
    "reviewer_2 = \"\"\"\n",
    "Official Review of Submission11061 by Reviewer RzZK\n",
    "Official Reviewby Reviewer RzZK04 Nov 2024, 06:59 (modified: 29 Nov 2024, 00:57)EveryoneRevisions\n",
    "Summary:\n",
    "This paper introduces NNsight and NDIF, two open systems that provide efficient, transparent access to the internals of large neural networks for research purposes. NNsight extends PyTorch to offer deferred remote execution of intervention graphs, while NDIF serves as a scalable inference service that executes these intervention requests, enabling resource sharing among users. The work addresses challenges like limited access to state-of-the-art models and the significant resource demands of large-scale AI research by sharing resources.\n",
    "\n",
    "Soundness: 2: fair\n",
    "Presentation: 3: good\n",
    "Contribution: 3: good\n",
    "Strengths:\n",
    "The intervention graph extends the model computational graph and decouples experimental design from model runtime, reducing engineering complexity.\n",
    "NDIF effectively shares GPU resources among researchers (co-tenancy), reducing cost and enabling large-scale experiments\n",
    "This is a novel idea with great potential benefit to the research community.\n",
    "Weaknesses:\n",
    "The evaluation section is limited to the end-to-end performance with little detail on the system optimizations. Specifically, more information is needed to assess the performance and scalability of this system using an increasing number of users.\n",
    "While NDIF addresses large-scale experiments on open models, it does not cover closed, proprietary models hosted proprietarily.\n",
    "Lack of discussion with relevant co-serving systems like S-LoRA (Sheng et al, MLSys 2024) and dLoRA (Wu et al, OSDI 2024).\n",
    "Questions:\n",
    "Could you please share more evaluation results on the performance and scalability of the proposed systems?\n",
    "\n",
    "Flag For Ethics Review: No ethics review needed.\n",
    "Rating: 6: marginally above the acceptance threshold\n",
    "Confidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\n",
    "Code Of Conduct: Yes\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TextBlock(citations=None, text='# Key Findings of \"NNsight and NDIF: Democratizing Access to Open-Weight Foundation Model Internals\"\\n\\nThis paper introduces two key technologies that work together to democratize access to large neural network internals:\\n\\n## Core Contributions\\n\\n1. **The Intervention Graph Architecture**: A framework for organizing experiments on large models that:\\n   - Decouples experiment design from model runtime\\n   - Reduces engineering burden\\n   - Enhances reproducibility\\n   - Enables low-cost communication with remote models\\n\\n2. **NNsight**: An open-source system extending PyTorch that:\\n   - Creates an expressive programming idiom for transparent model interventions\\n   - Allows researchers to inspect neural network internals without storing model parameters locally\\n   - Uses deferred computation graphs to enable remote execution\\n\\n3. **NDIF**: An open-source cloud inference service that:\\n   - Supports behind-the-scenes user sharing of model instances\\n   - Reduces costs of large-scale AI research\\n   - Provides safe co-tenancy of multiple researchers on shared infrastructure\\n\\n## Research Gap Identified\\n\\nThe authors conducted a quantitative survey of the machine learning literature revealing:\\n- A growing disparity between the most capable AI systems and those being studied by researchers\\n- 60.6% of surveyed research papers since February 2023 still study smaller, less performant models\\n- This gap is due to both engineering and infrastructural barriers, not just lack of capable models\\n\\n## Performance Benefits\\n\\nWhen compared to traditional approaches:\\n- NDIF eliminates model loading time, which scales nearly linearly with model size in HPC settings\\n- Remote execution introduces a roughly constant overhead regardless of model size\\n- The proposed approach becomes increasingly beneficial as parameter size grows\\n- NDIF significantly outperforms Petals (a peer-to-peer approach) for remote interventions\\n\\nThe paper demonstrates how this framework enables research on large models that would otherwise be unattainable for individual research groups due to computational, engineering, and financial constraints.', type='text')]\n"
     ]
    }
   ],
   "source": [
    "import anthropic\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# get API key\n",
    "load_dotenv()\n",
    "api_key = os.environ[\"ANTHROPIC_API_KEY\"]\n",
    "client = anthropic.Anthropic(api_key=api_key)\n",
    "\n",
    "\n",
    "message = client.messages.create(\n",
    "    model=\"claude-3-7-sonnet-20250219\",\n",
    "    system=\"You are an ICLR (international conference on learning representations) reviewer\",\n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"document\",\n",
    "                    \"source\": {\n",
    "                        \"type\": \"url\",\n",
    "                        \"url\": \"https://openreview.net/notes/edits/attachment?id=cxva7Lw6zB&name=pdf\",\n",
    "                    },\n",
    "                },\n",
    "                {\"type\": \"text\", \"text\": \"What are the key findings in this document?\"},\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "def get_completion(prompt: str):\n",
    "    message = client.messages.create(\n",
    "        model=\"claude-3-7-sonnet-20250219\",\n",
    "        system=\"You are an ICLR (International Conference on Learning Representations) reviewer\",\n",
    "        max_tokens=1024,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    )\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TextBlock(citations=None, text='# Key Findings of \"NNsight and NDIF: Democratizing Access to Open-Weight Foundation Model Internals\"\\n\\nThis paper introduces two key technologies that work together to democratize access to large neural network internals:\\n\\n## Core Contributions\\n\\n1. **The Intervention Graph Architecture**: A framework for organizing experiments on large models that:\\n   - Decouples experiment design from model runtime\\n   - Reduces engineering burden\\n   - Enhances reproducibility\\n   - Enables low-cost communication with remote models\\n\\n2. **NNsight**: An open-source system extending PyTorch that:\\n   - Creates an expressive programming idiom for transparent model interventions\\n   - Allows researchers to inspect neural network internals without storing model parameters locally\\n   - Uses deferred computation graphs to enable remote execution\\n\\n3. **NDIF**: An open-source cloud inference service that:\\n   - Supports behind-the-scenes user sharing of model instances\\n   - Reduces costs of large-scale AI research\\n   - Provides safe co-tenancy of multiple researchers on shared infrastructure\\n\\n## Research Gap Identified\\n\\nThe authors conducted a quantitative survey of the machine learning literature revealing:\\n- A growing disparity between the most capable AI systems and those being studied by researchers\\n- 60.6% of surveyed research papers since February 2023 still study smaller, less performant models\\n- This gap is due to both engineering and infrastructural barriers, not just lack of capable models\\n\\n## Performance Benefits\\n\\nWhen compared to traditional approaches:\\n- NDIF eliminates model loading time, which scales nearly linearly with model size in HPC settings\\n- Remote execution introduces a roughly constant overhead regardless of model size\\n- The proposed approach becomes increasingly beneficial as parameter size grows\\n- NDIF significantly outperforms Petals (a peer-to-peer approach) for remote interventions\\n\\nThe paper demonstrates how this framework enables research on large models that would otherwise be unattainable for individual research groups due to computational, engineering, and financial constraints.', type='text')]\n"
     ]
    }
   ],
   "source": [
    "print(message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__class_vars__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__fields__',\n",
       " '__fields_set__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__get_pydantic_core_schema__',\n",
       " '__get_pydantic_json_schema__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pretty__',\n",
       " '__private_attributes__',\n",
       " '__pydantic_complete__',\n",
       " '__pydantic_computed_fields__',\n",
       " '__pydantic_core_schema__',\n",
       " '__pydantic_custom_init__',\n",
       " '__pydantic_decorators__',\n",
       " '__pydantic_extra__',\n",
       " '__pydantic_fields__',\n",
       " '__pydantic_fields_set__',\n",
       " '__pydantic_generic_metadata__',\n",
       " '__pydantic_init_subclass__',\n",
       " '__pydantic_parent_namespace__',\n",
       " '__pydantic_post_init__',\n",
       " '__pydantic_private__',\n",
       " '__pydantic_root_model__',\n",
       " '__pydantic_serializer__',\n",
       " '__pydantic_validator__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__replace__',\n",
       " '__repr__',\n",
       " '__repr_args__',\n",
       " '__repr_name__',\n",
       " '__repr_recursion__',\n",
       " '__repr_str__',\n",
       " '__rich_repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_calculate_keys',\n",
       " '_check_frozen',\n",
       " '_copy_and_set_values',\n",
       " '_get_value',\n",
       " '_iter',\n",
       " 'citations',\n",
       " 'construct',\n",
       " 'copy',\n",
       " 'dict',\n",
       " 'from_orm',\n",
       " 'json',\n",
       " 'model_computed_fields',\n",
       " 'model_config',\n",
       " 'model_construct',\n",
       " 'model_copy',\n",
       " 'model_dump',\n",
       " 'model_dump_json',\n",
       " 'model_extra',\n",
       " 'model_fields',\n",
       " 'model_fields_set',\n",
       " 'model_json_schema',\n",
       " 'model_parametrized_name',\n",
       " 'model_post_init',\n",
       " 'model_rebuild',\n",
       " 'model_validate',\n",
       " 'model_validate_json',\n",
       " 'model_validate_strings',\n",
       " 'parse_file',\n",
       " 'parse_obj',\n",
       " 'parse_raw',\n",
       " 'schema',\n",
       " 'schema_json',\n",
       " 'text',\n",
       " 'to_dict',\n",
       " 'to_json',\n",
       " 'type',\n",
       " 'update_forward_refs',\n",
       " 'validate']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(message.content[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pydantic.main.BaseModel"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the base class that TextBlock inherits from\n",
    "type(message.content[0]).__bases__[0].__bases__[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Key Findings of \"NNsight and NDIF: Democratizing Access to Open-Weight Foundation Model Internals\"\n",
      "\n",
      "This paper introduces two key technologies that work together to democratize access to large neural network internals:\n",
      "\n",
      "## Core Contributions\n",
      "\n",
      "1. **The Intervention Graph Architecture**: A framework for organizing experiments on large models that:\n",
      "   - Decouples experiment design from model runtime\n",
      "   - Reduces engineering burden\n",
      "   - Enhances reproducibility\n",
      "   - Enables low-cost communication with remote models\n",
      "\n",
      "2. **NNsight**: An open-source system extending PyTorch that:\n",
      "   - Creates an expressive programming idiom for transparent model interventions\n",
      "   - Allows researchers to inspect neural network internals without storing model parameters locally\n",
      "   - Uses deferred computation graphs to enable remote execution\n",
      "\n",
      "3. **NDIF**: An open-source cloud inference service that:\n",
      "   - Supports behind-the-scenes user sharing of model instances\n",
      "   - Reduces costs of large-scale AI research\n",
      "   - Provides safe co-tenancy of multiple researchers on shared infrastructure\n",
      "\n",
      "## Research Gap Identified\n",
      "\n",
      "The authors conducted a quantitative survey of the machine learning literature revealing:\n",
      "- A growing disparity between the most capable AI systems and those being studied by researchers\n",
      "- 60.6% of surveyed research papers since February 2023 still study smaller, less performant models\n",
      "- This gap is due to both engineering and infrastructural barriers, not just lack of capable models\n",
      "\n",
      "## Performance Benefits\n",
      "\n",
      "When compared to traditional approaches:\n",
      "- NDIF eliminates model loading time, which scales nearly linearly with model size in HPC settings\n",
      "- Remote execution introduces a roughly constant overhead regardless of model size\n",
      "- The proposed approach becomes increasingly beneficial as parameter size grows\n",
      "- NDIF significantly outperforms Petals (a peer-to-peer approach) for remote interventions\n",
      "\n",
      "The paper demonstrates how this framework enables research on large models that would otherwise be unattainable for individual research groups due to computational, engineering, and financial constraints.\n"
     ]
    }
   ],
   "source": [
    "print(message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
